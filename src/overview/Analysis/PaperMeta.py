"""Meta Data extraction from pdf."""

import os
import re
from dataclasses import dataclass
from typing import Any, Dict, List, Optional

import fitz
import requests


@dataclass
class PaperMetadata:
    """Meta structure of paper metadata."""

    title: Optional[str]
    publication_year: Optional[int]
    cited_by_count: Optional[int]
    institution_lead: str
    openalex_url: Optional[str]
    pdf_url: Optional[str]
    authors: List[str]
    concepts: List[str]
    citation_trend_last_3y: Dict[int, int]
    abstract_full: Optional[str]


class PaperMetaAnalyzer:
    """PDFè®ºæ–‡åˆ†æå™¨"""

    HEADERS = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
    }

    DOI_PATTERN = r"\b(10\.\d{4,9}/[-._;()/:A-Z0-9]+)"
    ARXIV_PATTERN = r"arXiv:(\d{4}\.\d{4,5})"

    def __init__(self, file_paths: list[str]) -> None:
        self.session = requests.Session()
        self.session.headers.update(self.HEADERS)

        meta_data = []
        for file_path in file_paths:
            meta_data.append(self.get_paper_metadata(file_path))
            print(f"DONE : {file_path}\n")
        self.metadata = meta_data

    @staticmethod
    def reconstruct_abstract(
        inverted_index: Optional[Dict[str, List[int]]],
    ) -> Optional[str]:
        """å°†OpenAlexçš„å€’æ’ç´¢å¼•æ‘˜è¦è¿˜åŸä¸ºå¯è¯»æ–‡æœ¬"""
        if not inverted_index:
            return None

        # å±•å¹³ä¸º (ä½ç½®, å•è¯) å¯¹å¹¶æ’åº
        word_positions = [
            (pos, word)
            for word, positions in inverted_index.items()
            for pos in positions
        ]
        word_positions.sort(key=lambda x: x[0])

        return " ".join(word for _, word in word_positions)

    def extract_text_from_pdf(self, file_path: str) -> Optional[str]:
        """Exatract text from the first page of pdf."""
        try:
            with fitz.open(file_path) as doc:
                if len(doc) < 1:
                    print("âŒ PDF å†…å®¹ä¸ºç©º")
                    return None
                text = doc[0].get_text()
                return str(text) if text else None
        except Exception as e:
            print(f"âŒ PDFè¯»å–å¤±è´¥: {e}")
            return None

    def extract_ids_from_text(self, text: str) -> Dict[str, Optional[str]]:
        """ä»æ–‡æœ¬å’Œæ–‡ä»¶åä¸­æå–DOIå’ŒarXiv ID"""
        ids: Dict[str, Optional[str]] = {"doi": None, "arxiv": None}

        # æå–DOI
        doi_match = re.search(self.DOI_PATTERN, text, re.IGNORECASE)
        if doi_match:
            ids["doi"] = doi_match.group(1)
            print(f"âœ… æå–åˆ° DOI: {ids['doi']}")
            return ids

        arxiv_match = re.search(self.ARXIV_PATTERN, text, re.IGNORECASE)

        if arxiv_match:
            ids["arxiv"] = arxiv_match.group(1)
            return ids

        print("âŒ æœªèƒ½è¯†åˆ« DOI æˆ– arXiv IDã€‚è¯·æ£€æŸ¥ PDF æ˜¯å¦ä¸ºæ‰«æä»¶ã€‚")
        return ids

    def get_paper_metadata(self, file_path: str) -> Optional[Dict[str, Any]]:
        """ä¸»å…¥å£ï¼šä¼ å…¥PDFè·¯å¾„ï¼Œè¿”å›è¯¦ç»†çš„å…ƒæ•°æ®å­—å…¸"""
        if not os.path.exists(file_path):
            print(f"âŒ é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨ -> {file_path}")
            return None

        filename = os.path.basename(file_path)
        print(f"ğŸ“„ æ­£åœ¨åˆ†æ: {filename}")

        # æå–PDFæ–‡æœ¬
        text = self.extract_text_from_pdf(file_path)
        if not text:
            return None

        # æå–ID
        ids = self.extract_ids_from_text(text)

        # æ ¹æ®IDç±»å‹æŸ¥è¯¢
        doi = ids.get("doi")
        arxiv = ids.get("arxiv")

        if doi:
            return self.query_by_doi(doi)
        elif arxiv:
            clean_id = arxiv.split("v")[0]  # æ¸…æ´—ç‰ˆæœ¬å·
            return self.query_by_arxiv(clean_id)

        print("âŒ æœªèƒ½è¯†åˆ« DOI æˆ– arXiv IDã€‚è¯·æ£€æŸ¥ PDF æ˜¯å¦ä¸ºæ‰«æä»¶ã€‚")
        return None

    def query_by_doi(self, doi: str) -> Optional[Dict[str, Any]]:
        """é€šè¿‡DOIæŸ¥è¯¢OpenAlex"""
        doi_url = f"https://doi.org/{doi}" if not doi.startswith("http") else doi
        api_url = f"https://api.openalex.org/works/{doi_url}"
        print(f"ğŸ” [DOIæ¨¡å¼] æŸ¥è¯¢ OpenAlex: {doi}")
        return self._fetch_metadata(api_url, mode="direct")

    def query_by_arxiv(self, arxiv_id: str) -> Optional[Dict[str, Any]]:
        """é€šè¿‡arXiv IDæŸ¥è¯¢OpenAlex"""
        api_url = f"https://api.openalex.org/works?search={arxiv_id}"
        return self._fetch_metadata(api_url, mode="search")

    def _fetch_metadata(self, url: str, mode: str) -> Optional[Dict[str, Any]]:
        """ä»OpenAlex APIè·å–å…ƒæ•°æ®"""
        try:
            response = self.session.get(url, timeout=15)
            response.raise_for_status()

            data = response.json()
            result = self._extract_result(data, mode)
            if not result:
                return None

            return self._parse_metadata(result)

        except requests.RequestException as e:
            print(f"âŒ APIè¯·æ±‚å¤±è´¥: {e}")
            return None
        except Exception as e:
            print(f"âŒ æ•°æ®è§£æé”™è¯¯: {e}")
            return None

    def _extract_result(
        self, data: Dict[str, Any], mode: str
    ) -> Optional[Dict[str, Any]]:
        """ä»APIå“åº”ä¸­æå–ç»“æœ"""
        if mode == "search":
            if data["meta"]["count"] == 0:
                print("âŒ æœç´¢æœªæ‰¾åˆ°åŒ¹é…è®°å½•")
                return None
            return data["results"][0]  # å–ç½®ä¿¡åº¦æœ€é«˜çš„ç¬¬ä¸€æ¡
        return data  # ç›´æ¥æ¨¡å¼è¿”å›çš„å°±æ˜¯å¯¹è±¡

    def _parse_metadata(self, result: Dict[str, Any]) -> PaperMetadata:
        """è§£æOpenAlex APIè¿”å›çš„æ•°æ®"""
        # å¤„ç†æ‘˜è¦
        abstract_text = self.reconstruct_abstract(result.get("abstract_inverted_index"))
        abstract_preview = (
            abstract_text[:300] + "..." if abstract_text else "No Abstract Available"
        )

        # æå–ç¬¬ä¸€ä½œè€…æœºæ„
        institution = self._extract_institution(result)

        # æå–å¼•ç”¨è¶‹åŠ¿
        citation_trend = self._extract_citation_trend(result)

        return PaperMetadata(
            title=result.get("title"),
            publication_year=result.get("publication_year"),
            cited_by_count=result.get("cited_by_count"),
            institution_lead=institution,
            openalex_url=result.get("ids", {}).get("openalex"),
            pdf_url=result.get("open_access", {}).get("oa_url"),
            authors=self._extract_authors(result),
            concepts=self._extract_concepts(result),
            citation_trend_last_3y=citation_trend,
            abstract_full=abstract_text,
        )

    def _extract_institution(self, result: Dict[str, Any]) -> str:
        """æå–ç¬¬ä¸€ä½œè€…æœºæ„"""
        if result.get("authorships"):
            first_author = result["authorships"][0]
            if first_author.get("institutions"):
                return first_author["institutions"][0]["display_name"]
        return "Unknown"

    def _extract_authors(self, result: Dict[str, Any]) -> List[str]:
        """æå–ä½œè€…åˆ—è¡¨ï¼ˆå‰5ä½ï¼‰"""
        return [
            ship["author"]["display_name"] for ship in result.get("authorships", [])[:5]
        ]

    def _extract_concepts(self, result: Dict[str, Any]) -> List[str]:
        """æå–æ¦‚å¿µæ ‡ç­¾"""
        return [c["display_name"] for c in result.get("concepts", [])]

    def _extract_citation_trend(self, result: Dict[str, Any]) -> Dict[int, int]:
        """æå–æœ€è¿‘3å¹´çš„å¼•ç”¨è¶‹åŠ¿"""
        return {
            item["year"]: item["cited_by_count"]
            for item in result.get("counts_by_year", [])[:3]
        }


if __name__ == "__main__":
    from pprint import pprint

    result = PaperMetaAnalyzer(file_path="examples/Example/pdf/1706.03762v7.pdf")
    pprint(result.metadata)
